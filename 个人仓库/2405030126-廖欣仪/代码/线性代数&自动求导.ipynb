{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98c3e621-513a-4182-8628-727b8c5b90db",
   "metadata": {},
   "source": [
    "线性代数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bf64691-7ba6-45f4-a6ad-36587b1411ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.]), tensor([6.]), tensor([1.5000]), tensor([9.]))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "#标量\n",
    "x=torch.tensor([3.0])\n",
    "y=torch.tensor([2.0])\n",
    "x+y,x*y,x/y,x**y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "185bd595-3d53-4614-a836-87f474004b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#向量：标量组成的列表\n",
    "x=torch.arange(4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a37be12-d64e-4823-8038-72a310e412cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#索引访问任一元素\n",
    "x[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f0549f-7166-4686-bca9-0fe052d2a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#访问张量长度\n",
    "print(len(x))\n",
    "#形状\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbf0d86f-fe56-4672-a538-99a5dfce99ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11],\n",
      "        [12, 13, 14, 15],\n",
      "        [16, 17, 18, 19]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8, 12, 16],\n",
       "        [ 1,  5,  9, 13, 17],\n",
       "        [ 2,  6, 10, 14, 18],\n",
       "        [ 3,  7, 11, 15, 19]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#创建矩阵\n",
    "A=torch.arange(20).reshape(5,4)\n",
    "print(A)\n",
    "#转置\n",
    "A.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84dda6ad-0106-4291-8aec-95009e6c42ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [2, 0, 4],\n",
      "        [3, 4, 5]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True],\n",
       "        [True, True, True],\n",
       "        [True, True, True]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#对称矩阵--转置相同\n",
    "B=torch.tensor([[1,2,3],[2,0,4],[3,4,5]])\n",
    "print(B)\n",
    "B==B.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf056ff3-311e-418a-96e1-e1df9ce96e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵是向量的推广,构建更多轴的数据结构\n",
    "x=torch.arange(24).reshape(2,3,4)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0caf99a5-651f-49be-8c24-4bf0249be332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1.,  2.,  3.],\n",
       "         [ 4.,  5.,  6.,  7.],\n",
       "         [ 8.,  9., 10., 11.],\n",
       "         [12., 13., 14., 15.],\n",
       "         [16., 17., 18., 19.]]),\n",
       " tensor([[ 0.,  2.,  4.,  6.],\n",
       "         [ 8., 10., 12., 14.],\n",
       "         [16., 18., 20., 22.],\n",
       "         [24., 26., 28., 30.],\n",
       "         [32., 34., 36., 38.]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#形状相同的任何两个张量，按元素二元运算的结果都将相同\n",
    "A=torch.arange(20,dtype=torch.float32).reshape(5,4)\n",
    "B=A.clone()#通过分配新内存将A的一个副本分配给B\n",
    "A,A+B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8fc4fa88-4c10-405c-9333-3aa971a7d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   1.,   4.,   9.],\n",
      "        [ 16.,  25.,  36.,  49.],\n",
      "        [ 64.,  81., 100., 121.],\n",
      "        [144., 169., 196., 225.],\n",
      "        [256., 289., 324., 361.]])\n",
      "tensor([[ 0.,  2.,  4.,  6.],\n",
      "        [ 8., 10., 12., 14.],\n",
      "        [16., 18., 20., 22.],\n",
      "        [24., 26., 28., 30.],\n",
      "        [32., 34., 36., 38.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(190.)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#哈达玛积--乘法\n",
    "print(A*B)\n",
    "a=2\n",
    "#常数乘矩阵\n",
    "print(a*A)\n",
    "#所有元素求和\n",
    "A.sum()   #Asum(axis=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "55c4fa6a-73b9-4fee-9cc6-43267c3d5328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.,  4.],\n",
      "         [ 5.,  6.,  7.,  8.,  9.]],\n",
      "\n",
      "        [[10., 11., 12., 13., 14.],\n",
      "         [15., 16., 17., 18., 19.]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([40., 45., 50., 55.]),\n",
       " torch.Size([4]),\n",
       " tensor([ 6., 22., 38., 54., 70.]),\n",
       " torch.Size([5]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#指定轴求和\n",
    "print(A.reshape(2,2,5))\n",
    "A.sum(axis=0),A.sum(axis=0).shape,A.sum(axis=1),A.sum(axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "103b7ce3-1d4f-4c39-8bf7-98b1b66a8db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(9.5000) tensor(9.5000)\n",
      "tensor([ 8.,  9., 10., 11.]) tensor([ 8.,  9., 10., 11.])\n",
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  6.,  8., 10.],\n",
      "        [12., 15., 18., 21.],\n",
      "        [24., 28., 32., 36.],\n",
      "        [40., 45., 50., 55.]])\n"
     ]
    }
   ],
   "source": [
    "#均值\n",
    "print(A.mean(),A.sum()/A.numel())\n",
    "print(A.mean(axis=0),A.sum(axis=0)/A.shape[0])\n",
    "#累加求和\n",
    "print(A.cumsum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c1ed983-082f-47a9-b4e5-8034122f7b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 1., 2., 3.]) tensor([1., 1., 1., 1.]) tensor(6.)\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "#点积\n",
    "a=torch.tensor([0.0,1.0,2.0,3.0])\n",
    "b=torch.ones(4,dtype=torch.float32)\n",
    "print(a,b,torch.dot(a,b))\n",
    "#按元素乘法再求和\n",
    "print(torch.sum(a*b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0584fcd0-3e08-4f1e-bc46-169be63ec3d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.,  7.],\n",
      "        [ 8.,  9., 10., 11.],\n",
      "        [12., 13., 14., 15.],\n",
      "        [16., 17., 18., 19.]]) tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) tensor([0., 1., 2., 3.])\n",
      "tensor([ 14.,  38.,  62.,  86., 110.])\n",
      "tensor([[ 6.,  6.,  6.],\n",
      "        [22., 22., 22.],\n",
      "        [38., 38., 38.],\n",
      "        [54., 54., 54.],\n",
      "        [70., 70., 70.]])\n"
     ]
    }
   ],
   "source": [
    "B=torch.ones(4,3)\n",
    "print(A,B,a)\n",
    "#矩阵向量积\n",
    "print(torch.mv(A,a))\n",
    "#矩阵-矩阵乘法\n",
    "print(torch.mm(A,B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "389ba99a-fab9-43da-a603-6058587c51ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.)\n",
      "tensor(7.)\n",
      "tensor(6.)\n"
     ]
    }
   ],
   "source": [
    "#范式--长度\n",
    "u=torch.tensor([3.0,-4.0])\n",
    "print(torch.norm(u))\n",
    "#L1范数\n",
    "print(torch.abs(u).sum())\n",
    "#菲罗贝尼乌斯范数\n",
    "print(torch.norm(torch.ones((4,9))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb86af17-d690-40f2-b393-e5d9568f55db",
   "metadata": {},
   "source": [
    "矩阵计算"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf86d49-206a-41f6-98ad-936cbd461e6a",
   "metadata": {},
   "source": [
    "自动求导"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd1e303e-ab3d-4ae6-9d34-f1e34dffdf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 2., 3.])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.arange(4.0)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f196858d-bcb9-4594-ad1d-837b384c7a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(28., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#计算y关于x的梯度\n",
    "#先存储梯度\n",
    "x.requires_grad_(True)   #等价于x=torch.arange(4.0,requires_grad=True)\n",
    "x.grad              #默认值是None\n",
    "y=2*torch.dot(x,x)   #计算y\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5f3f0666-f4a1-48b5-bcb4-7a12e0c879ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  4.,  8., 12.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#反向传播函数\n",
    "y.backward()#求导\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f7a20a4-9158-40cf-910d-daede93b6665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad==4*x#验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5f5da861-55d5-404b-9e8f-f8499faeb5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1.])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#默认情况下PyTorch会累积梯度，需要清除之前的值\n",
    "x.grad.zero_()  #_表示重写之前的内容，zero表示把所有梯度清零#注释这行，运行结果变为[2,2,2,2]\n",
    "y=x.sum()\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18397e20-19b9-4eaa-ab0d-4ead0dac5916",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 2., 4., 6.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#非标量调用backward需要传入一个gradint参数\n",
    "x.grad.zero_()\n",
    "y=x*x\n",
    "#等价于y.backward(torch.ones(len(x)))\n",
    "y.sum().backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ee70125b-6990-413a-a8f2-220905036e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y=x*x\n",
    "u=y.detach()  #常数\n",
    "z=u*x\n",
    "\n",
    "z.sum().backward()\n",
    "x.grad==u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdb0541a-f594-4f69-9a11-4d04add07030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad.zero_()\n",
    "y.sum().backward()\n",
    "x.grad==2*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb1487-070a-45fd-9f7a-61712b3f818e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#构建函数的计算图需要通过python控制流\n",
    "def f(a):\n",
    "    b=a*2\n",
    "    while b.norm()<1000:\n",
    "        b=b*2\n",
    "    if b.sum()>0:\n",
    "        c=b\n",
    "    else:\n",
    "        c=100*b\n",
    "    return c\n",
    "\n",
    "a=torch.randn(size=(),requires_grad=True)\n",
    "d=f(a)\n",
    "d.backward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
