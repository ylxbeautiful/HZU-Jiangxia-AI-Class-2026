{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbea048e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      2\u001b[0m x\u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m12\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\u001b[38;5;66;03m#向量#tensor 是张量\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x= torch.arange(12)\n",
    "print(x)#向量#tensor 是张量\n",
    "#访问形状 .shape\n",
    "print(x.shape)\n",
    "#访问数量 .numel()\n",
    "print(x.numel())\n",
    "#改变形状不改变数量和元素值 .reshape\n",
    "x = x.reshape(3,4)\n",
    "print(x )\n",
    "#张量连接\n",
    "X = torch.arange(12,dtype = torch.float32).reshape(3,4)\n",
    "Y = torch.arange(12,dtype = torch.float32).reshape(3,4)\n",
    "print(X,Y)\n",
    "a = torch.cat((X,Y),dim=0)#上下叠加\n",
    "b = torch.cat((X,Y),dim=1)#左右叠加\n",
    "print(a,b)\n",
    "print(X == Y)#判断两个张量元素是否相同 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30d7bf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NumRooms</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pave</td>\n",
       "      <td>127500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>106000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NumRooms Alley   Price\n",
       "0       NaN  Pave  127500\n",
       "1       2.0   NaN  106000\n",
       "2       4.0   NaN  178100\n",
       "3       NaN   NaN  140000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
    "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
    "with open(data_file, 'w') as f:\n",
    "    f.write('NumRooms,Alley,Price\\n') #列名\n",
    "    f.write('NA,Pave,127500\\n')\n",
    "    f.write('2,NA,106000\\n')\n",
    "    f.write('4,NA,178100\\n')\n",
    "    f.write('NA,NA,140000\\n')\n",
    "#读取文件用到pandas\n",
    "data = pd.read_csv(data_file)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae58687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms\n",
      "0       3.0\n",
      "1       2.0\n",
      "2       4.0\n",
      "3       3.0\n"
     ]
    }
   ],
   "source": [
    "#将NaN填充 用到fillna\n",
    "inputs,outputs= data.iloc[:,0:1] ,data.iloc[:,2] # 提取第1、2列（NumRooms和Alley）\n",
    "inputs = inputs.fillna(inputs.mean())  # 用均值填充NaN\n",
    "print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0e9957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NumRooms   Price  Alley_Pave  Alley_nan\n",
      "0       NaN  127500        True      False\n",
      "1       2.0  106000       False       True\n",
      "2       4.0  178100       False       True\n",
      "3       NaN  140000       False       True\n"
     ]
    }
   ],
   "source": [
    "#区别于离散值将NaN为一个类别\n",
    "inputs = pd.get_dummies(data,dummy_na=True)\n",
    "print (inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ba3decd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#标量的概念 一个元素即为标量\n",
    "x = torch.Tensor([3.0])\n",
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a169719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#标量组成的列表即为向量\n",
    "y = torch.arange(4)\n",
    "y\n",
    "#元素的访问\n",
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8947a86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#张量长度的访问\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b96cfbfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵的创建 先构建再重构\n",
    "a = torch.arange(12).reshape(3,4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c577fa15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  4,  8],\n",
       "        [ 1,  5,  9],\n",
       "        [ 2,  6, 10],\n",
       "        [ 3,  7, 11]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#矩阵的转置 \n",
    "a.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8c56385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3,  4],\n",
      "         [ 5,  6,  7,  8,  9]],\n",
      "\n",
      "        [[10, 11, 12, 13, 14],\n",
      "         [15, 16, 17, 18, 19]]])\n"
     ]
    }
   ],
   "source": [
    "#多维矩阵如何创建\n",
    "B = torch.arange(20).reshape(2,2,5)#从左到右 2为维度 2 为行 5为列 \n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "158067b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(190)\n"
     ]
    }
   ],
   "source": [
    "#对元素求和\n",
    "print(B.sum())#永远都为标量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ac5271d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10, 12, 14, 16, 18],\n",
      "        [20, 22, 24, 26, 28]])\n",
      "tensor([[ 5,  7,  9, 11, 13],\n",
      "        [25, 27, 29, 31, 33]])\n",
      "tensor([[10, 35],\n",
      "        [60, 85]])\n"
     ]
    }
   ],
   "source": [
    "#对指定维度求和\n",
    "B_sum_axis0 = B.sum(axis=0) #把多个矩阵的 “对应位置元素” 相加（即第 0 个矩阵的 (行，列) 和 第 1 个矩阵的 (行，列) 相加），求和后第 0 轴消失，结果维度变为 (3, 4)（3 行 4 列的二维矩阵）\n",
    "print(B_sum_axis0)\n",
    "B_sum_axis1 = B.sum(axis=1)#对每个矩阵单独处理，把同一矩阵内的 “每行元素沿列方向相加”（即每个矩阵的所有行求和合并为 1 行），求和后第 1 轴消失，结果维度变为 (2, 4)（2 个矩阵，每个矩阵 1 行 4 列）。\n",
    "print(B_sum_axis1)\n",
    "B_sum_axis2 = B.sum(axis=2)#对每个矩阵单独处理，把同一矩阵内的 “每列元素沿行方向相加”（即每个矩阵的每行求和合并为 1 列），求和后第 2 轴消失，结果维度变为 (2, 3)（2 个矩阵，每个矩阵 3 行 1 列）。\n",
    "print(B_sum_axis2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "068be862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5000)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#求平均值 mean()\n",
    "Q = torch.arange(12,dtype=torch.float).reshape(2,3,2)#求平均值一定得为浮点数如果是整数无法求平均值\n",
    "Q.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "13da826c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[3., 4.],\n",
      "         [5., 6.],\n",
      "         [7., 8.]]])\n"
     ]
    }
   ],
   "source": [
    "#维度求均值\n",
    "Q_mean_axis0 = Q.mean(axis = 0,keepdim=True)#keepdim 是防止降维的\n",
    "print(Q_mean_axis0 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fd1980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.],\n",
      "         [ 2.,  3.],\n",
      "         [ 4.,  5.]],\n",
      "\n",
      "        [[ 6.,  8.],\n",
      "         [10., 12.],\n",
      "         [14., 16.]]])\n"
     ]
    }
   ],
   "source": [
    "#累加求和\n",
    "z =Q.cumsum(axis = 0)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e1448e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "#自动求导\n",
    "c = torch.arange(4,dtype=float)\n",
    "c.requires_grad_(True)#用于存储x的梯度\n",
    "c.grad#默认为None\n",
    "print(c.grad)\n",
    "s = 2 * torch.dot(c,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c529adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正向求导结果：\n",
      "x=2时，y=15，dy/dx=7\n",
      "\n",
      "反向求导结果：\n",
      "x=2时，y=15，dy/dx=7\n"
     ]
    }
   ],
   "source": [
    "#正向反向求导思路\n",
    "import numpy as np\n",
    "def forward_derivative(x):\n",
    "    \"\"\"\n",
    "    正向求导：计算 y = x² + 3x + 5 在x处的导数 dy/dx\n",
    "    步骤：\n",
    "    1. 计算中间变量：a = x², b = 3x, c = 5\n",
    "    2. 正向计算各中间变量对x的导数，再通过链式法则求dy/dx\n",
    "    \"\"\"\n",
    "    # 第一步：计算函数值和中间变量\n",
    "    a = x **2  # 中间变量a = x²\n",
    "    b = 3 * x   # 中间变量b = 3x\n",
    "    y = a + b + 5  # 最终输出y\n",
    "    # 第二步：正向求导（按计算顺序求导）\n",
    "    da_dx = 2 * x  # a对x的导数：d(x²)/dx = 2x\n",
    "    db_dx = 3      # b对x的导数：d(3x)/dx = 3\n",
    "    dc_dx = 0      # 常数5对x的导数为0\n",
    "    dy_dx = da_dx + db_dx + dc_dx  # 链式法则：dy/dx = da/dx + db/dx + dc/dx\n",
    "    return y, dy_dx\n",
    "def backward_derivative(x):\n",
    "    \"\"\"\n",
    "    反向求导：从输出y反向计算各变量对x的导数\n",
    "    步骤：\n",
    "    1. 先计算所有中间变量和最终输出（和正向计算一致）\n",
    "    2. 从输出y开始，反向计算每个中间变量的导数（链式法则反向应用）\n",
    "    \"\"\"\n",
    "    # 第一步：正向计算中间变量和输出（和正向求导的第一步一致）\n",
    "    a = x** 2\n",
    "    b = 3 * x\n",
    "    y = a + b + 5\n",
    "    # 第二步：反向求导（从输出往输入推）\n",
    "    dy_dy = 1  # 输出对自身的导数为1（起点）\n",
    "    # y = a + b + 5 → dy/da = 1, dy/db = 1, dy/dc = 1\n",
    "    dy_da = dy_dy * 1\n",
    "    dy_db = dy_dy * 1\n",
    "    dy_dc = dy_dy * 1\n",
    "    # 反向计算a、b对x的导数，并传递梯度\n",
    "    da_dx = 2 * x\n",
    "    db_dx = 3\n",
    "    dc_dx = 0\n",
    "    # 最终dy/dx = dy/da * da/dx + dy/db * db/dx + dy/dc * dc/dx\n",
    "    dy_dx = dy_da * da_dx + dy_db * db_dx + dy_dc * dc_dx\n",
    "    return y, dy_dx\n",
    "if __name__ == \"__main__\":\n",
    "    # 测试x=2时的导数（理论值：dy/dx=2x+3 → x=2时导数为7）\n",
    "    x_test = 2\n",
    "    # 正向求导结果\n",
    "    y_forward, dy_dx_forward = forward_derivative(x_test)\n",
    "    print(f\"正向求导结果：\")\n",
    "    print(f\"x={x_test}时，y={y_forward}，dy/dx={dy_dx_forward}\")\n",
    "    # 反向求导结果\n",
    "    y_backward, dy_dx_backward = backward_derivative(x_test)\n",
    "    print(f\"\\n反向求导结果：\")\n",
    "    print(f\"x={x_test}时，y={y_backward}，dy/dx={dy_dx_backward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ad452d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.,  4.,  8., 12.], dtype=torch.float64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0.], dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#反向传播求导\n",
    "s.backward()#只能触发一次 如果要第二次触发则得清空\n",
    "print(c.grad)\n",
    "c.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fb953a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#python 梯度会累计。所以计算之前得清空之前的值\n",
    "c.grad.zero_()#清空\n",
    "y = c.sum()\n",
    "y.backward()\n",
    "print(c.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a550c50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== 原始带问题的张量 =====\n",
      "tensor([[         -1,          -1,           0],\n",
      "        [-2147483648,           0,           0],\n",
      "        [          0,          -2,         100],\n",
      "        [         -1, -2147483648,           0],\n",
      "        [          0,           1,           0],\n",
      "        [        -50,           0,           0],\n",
      "        [          0,           0,           0],\n",
      "        [-2147483648, -2147483648, -2147483648],\n",
      "        [         -1,          -1,           0],\n",
      "        [         -1,          -1,           0]], dtype=torch.int32)\n",
      "原始张量形状： torch.Size([10, 3])\n",
      "\n",
      "===== 步骤1：类型转换（int32 → float32） =====\n",
      "torch.float32\n",
      "\n",
      "===== 步骤2：处理缺失值（删除全NaN行 + 均值填充剩余NaN） =====\n",
      "tensor([[-1.0000e+00, -1.0000e+00,  0.0000e+00],\n",
      "        [-2.1475e+09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.0000e+00,  1.0000e+02],\n",
      "        [-1.0000e+00, -2.1475e+09,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
      "        [-5.0000e+01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1475e+09, -2.1475e+09, -2.1475e+09],\n",
      "        [-1.0000e+00, -1.0000e+00,  0.0000e+00],\n",
      "        [-1.0000e+00, -1.0000e+00,  0.0000e+00]])\n",
      "\n",
      "===== 步骤3：处理异常值（3σ原则） =====\n",
      "tensor([[-1.0000e+00, -1.0000e+00,  0.0000e+00],\n",
      "        [-2.1475e+09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.0000e+00,  1.0000e+02],\n",
      "        [-1.0000e+00, -2.1475e+09,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
      "        [-5.0000e+01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1475e+09, -2.1475e+09, -2.1475e+09],\n",
      "        [-1.0000e+00, -1.0000e+00,  0.0000e+00],\n",
      "        [-1.0000e+00, -1.0000e+00,  0.0000e+00]])\n",
      "\n",
      "===== 步骤4：删除重复行 =====\n",
      "tensor([[-1.0000e+00, -1.0000e+00,  0.0000e+00],\n",
      "        [-2.1475e+09,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00, -2.0000e+00,  1.0000e+02],\n",
      "        [-1.0000e+00, -2.1475e+09,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.0000e+00,  0.0000e+00],\n",
      "        [-5.0000e+01,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [-2.1475e+09, -2.1475e+09, -2.1475e+09]])\n",
      "\n",
      "===== 步骤5：数据标准化（均值0，方差1） =====\n",
      "tensor([[ 0.5401,  0.5401,  0.3536],\n",
      "        [-1.6202,  0.5401,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [ 0.5401, -1.6202,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [-1.6202, -1.6202, -2.4749]])\n",
      "标准化后每列均值（接近0）： tensor([0., 0., 0.])\n",
      "标准化后每列方差（接近1）： tensor([1.0000, 1.0000, 1.0000])\n",
      "\n",
      "===== 最终清洗后的张量 =====\n",
      "tensor([[ 0.5401,  0.5401,  0.3536],\n",
      "        [-1.6202,  0.5401,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [ 0.5401, -1.6202,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [ 0.5401,  0.5401,  0.3536],\n",
      "        [-1.6202, -1.6202, -2.4749]])\n",
      "最终张量形状： torch.Size([8, 3])\n"
     ]
    }
   ],
   "source": [
    "#数据处理演练\n",
    "# 生成形状为(10, 3)的张量：10行（样本），3列（特征）\n",
    "# 包含：NaN（缺失值）、极端值（异常值）、重复行、整数类型\n",
    "torch.manual_seed(0)  # 固定随机种子，结果可复现\n",
    "raw_data = torch.randn(10, 3)  # 正态分布随机数\n",
    "# 手动插入缺失值（NaN）\n",
    "raw_data[1, 0] = float('nan')  # 第2行第1列\n",
    "raw_data[3, 1] = float('nan')  # 第4行第2列\n",
    "raw_data[7, :] = float('nan')  # 第8行全部缺失\n",
    "# 插入异常值（极端值，比如远大于/小于正常范围）\n",
    "raw_data[2, 2] = 100.0  # 第3行第3列\n",
    "raw_data[5, 0] = -50.0  # 第6行第1列\n",
    "# 插入重复行\n",
    "raw_data[8] = raw_data[0]  # 第9行 = 第1行\n",
    "raw_data[9] = raw_data[0]  # 第10行 = 第1行\n",
    "# 转换为整数类型（模拟类型不匹配问题）\n",
    "raw_data = raw_data.to(torch.int32)\n",
    "\n",
    "print(\"===== 原始带问题的张量 =====\")\n",
    "print(raw_data)\n",
    "print(\"原始张量形状：\", raw_data.shape)\n",
    "cleaned_data = raw_data.clone()  # 复制张量，避免修改原数据\n",
    "# 步骤1：类型转换（转为浮点型，方便后续数值计算）\n",
    "cleaned_data = cleaned_data.to(torch.float32)\n",
    "print(\"\\n===== 步骤1：类型转换（int32 → float32） =====\")\n",
    "print(cleaned_data.dtype)\n",
    "# 步骤2：处理缺失值（NaN）\n",
    "# 方案A：删除全为NaN的行（常用）\n",
    "# 先判断每行是否有非NaN值，保留非全NaN的行\n",
    "mask_not_all_nan = ~torch.isnan(cleaned_data).all(dim=1)\n",
    "cleaned_data = cleaned_data[mask_not_all_nan]\n",
    "# 方案B：用列均值填充剩余的NaN（常用，替代删除）\n",
    "# 计算每列的均值（忽略NaN）\n",
    "col_means = torch.nanmean(cleaned_data, dim=0)\n",
    "# 遍历每列，填充NaN为对应列的均值\n",
    "for col in range(cleaned_data.shape[1]):\n",
    "    nan_mask = torch.isnan(cleaned_data[:, col])\n",
    "    cleaned_data[nan_mask, col] = col_means[col]\n",
    "print(\"\\n===== 步骤2：处理缺失值（删除全NaN行 + 均值填充剩余NaN） =====\")\n",
    "print(cleaned_data)\n",
    "# 步骤3：处理异常值（极端值）\n",
    "# 方法：用“3σ原则”（正态分布中，99.7%数据在±3σ内）识别异常值，替换为边界值\n",
    "for col in range(cleaned_data.shape[1]):\n",
    "    col_data = cleaned_data[:, col]\n",
    "    mean = torch.mean(col_data)\n",
    "    std = torch.std(col_data)\n",
    "    # 计算上下边界\n",
    "    upper_bound = mean + 3 * std\n",
    "    lower_bound = mean - 3 * std\n",
    "    # 替换超过上边界的值为上边界，低于下边界的值为下边界\n",
    "    cleaned_data[col_data > upper_bound, col] = upper_bound\n",
    "    cleaned_data[col_data < lower_bound, col] = lower_bound\n",
    "print(\"\\n===== 步骤3：处理异常值（3σ原则） =====\")\n",
    "print(cleaned_data)\n",
    "# 步骤4：删除重复行\n",
    "# 方法：将张量转为numpy（PyTorch无直接去重API），去重后转回张量\n",
    "# 注意：仅适合小规模张量，大规模数据建议用Pandas先处理\n",
    "cleaned_np = cleaned_data.numpy()\n",
    "# 去重：axis=0表示按行去重，return_index=True返回保留行的索引\n",
    "_, unique_indices = np.unique(cleaned_np, axis=0, return_index=True)\n",
    "unique_indices = sorted(unique_indices)  # 保持原顺序\n",
    "cleaned_data = torch.tensor(cleaned_np[unique_indices])\n",
    "print(\"\\n===== 步骤4：删除重复行 =====\")\n",
    "print(cleaned_data)\n",
    "# 步骤5：数据标准化（可选，深度学习常用，使数据均值为0、方差为1）\n",
    "# 计算每列的均值和标准差\n",
    "col_mean = torch.mean(cleaned_data, dim=0)\n",
    "col_std = torch.std(cleaned_data, dim=0)\n",
    "# 标准化：(x - 均值) / 标准差（避免除以0，加极小值）\n",
    "cleaned_data = (cleaned_data - col_mean) / (col_std + 1e-8)\n",
    "\n",
    "print(\"\\n===== 步骤5：数据标准化（均值0，方差1） =====\")\n",
    "print(cleaned_data)\n",
    "print(\"标准化后每列均值（接近0）：\", torch.mean(cleaned_data, dim=0))\n",
    "print(\"标准化后每列方差（接近1）：\", torch.var(cleaned_data, dim=0))\n",
    "print(\"\\n===== 最终清洗后的张量 =====\")\n",
    "print(cleaned_data)\n",
    "print(\"最终张量形状：\", cleaned_data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
