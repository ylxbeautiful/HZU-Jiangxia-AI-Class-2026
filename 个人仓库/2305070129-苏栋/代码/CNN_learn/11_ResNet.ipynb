{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 残差网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差块（Residual Block）是残差网络（ResNet）的基本结构，它通过引入快捷连接（shortcut connections）来缓解深度神经网络中的梯度消失问题。残差块的主要思想是让网络学习输入和输出之间的残差函数，而不是直接学习输入到输出的映射。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2lzh as d2l\n",
    "from mxnet.gluon import nn\n",
    "from mxnet import init, nd,gluon\n",
    "\n",
    "class Residual(nn.Block):\n",
    "    def __init__(self,num_channels,use_1x1conv=False,strides=1,**kwargs):\n",
    "        super(Residual,self).__init__(**kwargs)\n",
    "        self.conv1=nn.Conv2D(num_channels,kernel_size=3,padding=1,strides=strides)\n",
    "        self.conv2=nn.Conv2D(num_channels,kernel_size=3,padding=1)\n",
    "        if use_1x1conv:\n",
    "            self.conv3=nn.Conv2D(num_channels,kernel_size=1,strides=strides)\n",
    "        else:\n",
    "            self.conv3=None\n",
    "        self.bn1=nn.BatchNorm()\n",
    "        self.bn2=nn.BatchNorm()\n",
    "\n",
    "    def forward(self,X):\n",
    "        Y=nd.relu(self.bn1(self.conv1(X)))\n",
    "        Y=self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X=self.conv3(X)\n",
    "        return nd.relu(Y+X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 3, 6, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk=Residual(3)\n",
    "blk.initialize()\n",
    "X=nd.random.normal(shape=(4,3,6,6)) # 4个样本，3个通道，6*6的图像\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 6, 3, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk=Residual(6,use_1x1conv=True,strides=2) # 通道数从3变为6，步幅为2\n",
    "blk.initialize()\n",
    "blk(X).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net=nn.Sequential()\n",
    "net.add(nn.Conv2D(64,kernel_size=7,strides=2,padding=3),\n",
    "       nn.BatchNorm(),\n",
    "       nn.Activation('relu'),\n",
    "       nn.MaxPool2D(pool_size=3,strides=2,padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_block(num_channels,num_residuals,first_block=False):\n",
    "    blk=nn.Sequential()\n",
    "    for i in range(num_residuals):\n",
    "        if i==0 and not first_block:\n",
    "            blk.add(Residual(num_channels,use_1x1conv=True,strides=2)) \n",
    "        else:\n",
    "            blk.add(Residual(num_channels))\n",
    "    return blk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.add(resnet_block(64,2,first_block=True),\n",
    "       resnet_block(128,2),\n",
    "       resnet_block(256,2),\n",
    "       resnet_block(512,2))\n",
    "net.add(nn.GlobalAvgPool2D(),\n",
    "       nn.Dense(10)) # 加入全局平均池化层和全连接层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv7 output shape:\t (1, 64, 112, 112)\n",
      "batchnorm6 output shape:\t (1, 64, 112, 112)\n",
      "relu0 output shape:\t (1, 64, 112, 112)\n",
      "pool0 output shape:\t (1, 64, 56, 56)\n",
      "sequential1 output shape:\t (1, 64, 56, 56)\n",
      "sequential2 output shape:\t (1, 128, 28, 28)\n",
      "sequential3 output shape:\t (1, 256, 14, 14)\n",
      "sequential4 output shape:\t (1, 512, 7, 7)\n",
      "pool1 output shape:\t (1, 512, 1, 1)\n",
      "dense0 output shape:\t (1, 10)\n"
     ]
    }
   ],
   "source": [
    "net.initialize()\n",
    "X=nd.random.uniform(shape=(1,1,224,224))\n",
    "for layer in net:\n",
    "    X=layer(X)\n",
    "    print(layer.name,'output shape:\\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取数据和训练模型\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mxnet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
